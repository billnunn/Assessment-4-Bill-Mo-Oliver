{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "479bc288-3823-4f55-ad63-69bda62492d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86fee258-7107-44b8-ae51-6e0590b8eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111cdabf-4e2e-4903-b92b-f910bfe83825",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8470c68d-34a6-48ed-8956-7cdbe3ec1029",
   "metadata": {},
   "source": [
    "Loading pre-processed data from [Assessment 1](https://github.com/billnunn/Assessment-1-Bill-Mo). This was a fairly clean dataset and the pre-processing was thoroughly done with appropriate manual scaling and then subsequently ran on RandomForest classifiers. The data should remain appropriate for DNN though it may not be complex enough to necessarily require a DNN as a classifier (particularly as RandomForests already did a good job in the assessment above). \n",
    "\n",
    "Nevertheless, this dataset should still allow for comparison between optimizers which is the scientific question that this report asks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f83bb6f-6c24-4fc9-ab2f-89809cdbc407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "      <th>connection_type</th>\n",
       "      <th>connection_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.204007</td>\n",
       "      <td>8.603554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.480639</td>\n",
       "      <td>6.188264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.463832</td>\n",
       "      <td>7.198931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.393628</td>\n",
       "      <td>7.198931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.384495</td>\n",
       "      <td>7.617268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  urgent  hot  num_failed_logins  \\\n",
       "0       0.0   5.204007   8.603554     0.0  0.0                0.0   \n",
       "1       0.0   5.480639   6.188264     0.0  0.0                0.0   \n",
       "2       0.0   5.463832   7.198931     0.0  0.0                0.0   \n",
       "3       0.0   5.393628   7.198931     0.0  0.0                0.0   \n",
       "4       0.0   5.384495   7.617268     0.0  0.0                0.0   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files  ...  \\\n",
       "0              0.0       0.0                 0.0               0.0  ...   \n",
       "1              0.0       0.0                 0.0               0.0  ...   \n",
       "2              0.0       0.0                 0.0               0.0  ...   \n",
       "3              0.0       0.0                 0.0               0.0  ...   \n",
       "4              0.0       0.0                 0.0               0.0  ...   \n",
       "\n",
       "   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "0          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "1          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "2          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "3          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "4          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "\n",
       "   flag_SH  connection_type  connection_category  \n",
       "0      0.0           normal               normal  \n",
       "1      0.0           normal               normal  \n",
       "2      0.0           normal               normal  \n",
       "3      0.0           normal               normal  \n",
       "4      0.0           normal               normal  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/kdd_log_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb1a5d-44f1-47d2-982e-3f3c6b44ce6e",
   "metadata": {},
   "source": [
    "KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea1fa57-5bcb-4632-b0b0-59770370ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# from sklearn.model_selection import KFold\n",
    "# kf = KFold(n_splits=10,shuffle=True)\n",
    "# kfsplit=kf.split(df)\n",
    "# ## We're going to extract out the \"test\" dataset from the first fold, to do our testing on\n",
    "# # kf.split returns an iterator, i.e. it creates a function that creates a test/split\n",
    "# # which we can either loop over or get the first using next\n",
    "# ninefolds,onefold = next(kfsplit) \n",
    "# train_data = df.loc[ninefolds]\n",
    "# test_data = df.loc[onefold]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d6805-3e96-45e9-afc1-345cc143f223",
   "metadata": {},
   "source": [
    "Examine the labels for our dataset. We have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "360514c9-35a7-45f4-aaa9-fb543a93290a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 23 connection types and 5 connection categories\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "connection_type  connection_category\n",
       "smurf            dos                    280790\n",
       "neptune          dos                    107201\n",
       "normal           normal                  97278\n",
       "back             dos                      2203\n",
       "satan            probe                    1589\n",
       "ipsweep          probe                    1247\n",
       "portsweep        probe                    1040\n",
       "warezclient      r2l                      1020\n",
       "teardrop         dos                       979\n",
       "pod              dos                       264\n",
       "nmap             probe                     231\n",
       "guess_passwd     r2l                        53\n",
       "buffer_overflow  u2r                        30\n",
       "land             dos                        21\n",
       "warezmaster      r2l                        20\n",
       "imap             r2l                        12\n",
       "rootkit          u2r                        10\n",
       "loadmodule       u2r                         9\n",
       "ftp_write        r2l                         8\n",
       "multihop         r2l                         7\n",
       "phf              r2l                         4\n",
       "perl             u2r                         3\n",
       "spy              r2l                         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_type = df.connection_type.nunique()\n",
    "num_cat = df.connection_category.nunique()\n",
    "print('Total of {} connection types and {} connection categories'.format(num_type,num_cat))\n",
    "print()\n",
    "df[['connection_type','connection_category']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99fa1d8d-123e-4f06-a94a-df55ca0709cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b19081-08b1-4be5-a85e-b11850ab5289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['connection_type', 'connection_category'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5a160ce-3733-42a4-bb90-8c0fddf4027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[df.columns[:-2]]\n",
    "targets = df[df.columns[-2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d96e75f8-3f93-4ec2-b65a-e080faf7eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, targets,\n",
    "                                                    test_size=0.5, \n",
    "                                                    random_state = 42, shuffle = True, \n",
    "                                                    stratify = targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1349659-3752-4d86-9f20-07cc8c00ce3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112306</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404506</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.255750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222435</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.940222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234492</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.940222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration  src_bytes  dst_bytes  urgent  hot  num_failed_logins  \\\n",
       "360984       0.0   0.000000        0.0     0.0  0.0                0.0   \n",
       "112306       0.0   0.000000        0.0     0.0  0.0                0.0   \n",
       "404506       0.0   6.255750        0.0     0.0  0.0                0.0   \n",
       "222435       0.0   6.940222        0.0     0.0  0.0                0.0   \n",
       "234492       0.0   6.940222        0.0     0.0  0.0                0.0   \n",
       "\n",
       "        num_compromised  num_root  num_file_creations  num_access_files  ...  \\\n",
       "360984              0.0       0.0                 0.0               0.0  ...   \n",
       "112306              0.0       0.0                 0.0               0.0  ...   \n",
       "404506              0.0       0.0                 0.0               0.0  ...   \n",
       "222435              0.0       0.0                 0.0               0.0  ...   \n",
       "234492              0.0       0.0                 0.0               0.0  ...   \n",
       "\n",
       "        flag_REJ  flag_RSTO  flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  \\\n",
       "360984       0.0        0.0          0.0        0.0      1.0      0.0   \n",
       "112306       0.0        0.0          0.0        0.0      1.0      0.0   \n",
       "404506       0.0        0.0          0.0        0.0      0.0      0.0   \n",
       "222435       0.0        0.0          0.0        0.0      0.0      0.0   \n",
       "234492       0.0        0.0          0.0        0.0      0.0      0.0   \n",
       "\n",
       "        flag_S2  flag_S3  flag_SF  flag_SH  \n",
       "360984      0.0      0.0      0.0      0.0  \n",
       "112306      0.0      0.0      0.0      0.0  \n",
       "404506      0.0      0.0      1.0      0.0  \n",
       "222435      0.0      0.0      1.0      0.0  \n",
       "234492      0.0      0.0      1.0      0.0  \n",
       "\n",
       "[5 rows x 115 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd94db0c-c38c-44d2-99a0-e8d3327790a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>connection_type</th>\n",
       "      <th>connection_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360984</th>\n",
       "      <td>neptune</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112306</th>\n",
       "      <td>neptune</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404506</th>\n",
       "      <td>smurf</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222435</th>\n",
       "      <td>smurf</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234492</th>\n",
       "      <td>smurf</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       connection_type connection_category\n",
       "360984         neptune                 dos\n",
       "112306         neptune                 dos\n",
       "404506           smurf                 dos\n",
       "222435           smurf                 dos\n",
       "234492           smurf                 dos"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34d07d66-fb3e-42d4-a9a8-db31e3cf8a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 23)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.connection_type.nunique(), y_test.connection_type.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8046ea51-722f-4dfe-8fb1-0df78c2dc8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : smurf dos has difference: 0\n",
      "Index : neptune dos has difference: -1\n",
      "Index : normal normal has difference: 0\n",
      "Index : back dos has difference: -1\n",
      "Index : satan probe has difference: -1\n",
      "Index : ipsweep probe has difference: -1\n",
      "Index : portsweep probe has difference: 0\n",
      "Index : warezclient r2l has difference: 0\n",
      "Index : teardrop dos has difference: -1\n",
      "Index : pod dos has difference: 0\n",
      "Index : nmap probe has difference: -1\n",
      "Index : guess_passwd r2l has difference: 1\n",
      "Index : buffer_overflow u2r has difference: 0\n",
      "Index : land dos has difference: 1\n",
      "Index : warezmaster r2l has difference: 0\n",
      "Index : imap r2l has difference: 0\n",
      "Index : rootkit u2r has difference: 0\n",
      "Index : loadmodule u2r has difference: 1\n",
      "Index : ftp_write r2l has difference: 0\n",
      "Index : multihop r2l has difference: 1\n",
      "Index : perl u2r has difference: 1\n",
      "Index : phf r2l has difference: 0\n",
      "Index : spy r2l has difference: 0\n"
     ]
    }
   ],
   "source": [
    "differences = [(ind, y_train.value_counts()[ind] - y_test.value_counts()[ind]) for ind in y_train.value_counts().index]\n",
    "\n",
    "for a in differences:\n",
    "    print('Index :', a[0][0], a[0][1], 'has difference:', a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2749c6a-acb3-49fa-a743-1235cbed4ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dos       195728\n",
       "normal     48639\n",
       "probe       2052\n",
       "r2l          564\n",
       "u2r           27\n",
       "Name: connection_category, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.connection_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3680da4-7dea-42fa-88ae-1f48750cce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small, X_val, y_train_small, y_val = train_test_split(X_train, y_train, \n",
    "                                                             test_size = 0.8,\n",
    "                                                             random_state = 42, shuffle = True,\n",
    "                                                             stratify = y_train.connection_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa78eb6c-15df-4990-a7bc-f98556a6dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn target into binary with 0 = normal, 1 = attack\n",
    "y_train_bin = y_train_small.connection_category.apply(lambda x: 0 if x == 'normal' else 1)\n",
    "y_val_bin = y_val.connection_category.apply(lambda x: 0 if x == 'normal' else 1)\n",
    "y_test_bin = y_test.connection_category.apply(lambda x: 0 if x == 'normal' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "09129596-1360-4dc7-95e5-e9504daa4c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create multi category classifier variable e.g. normal,u2r,dos... \n",
    "#these will get loaded slightly differently into the other files\n",
    "y_train_multi = y_train_small.connection_category\n",
    "y_val_multi = y_val.connection_category\n",
    "y_test_multi = y_test.connection_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4776cfd-afe1-41bc-9d94-3d412e899110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #last 2 columns are labels so we do not grab them for our X\n",
    "# X_train = train_data[train_data.columns[:-2]]\n",
    "# X_test = test_data[test_data.columns[:-2]]\n",
    "\n",
    "\n",
    "# #create binary label arrays for attack/not attack \n",
    "# y_train_bin = train_data.connection_category.copy()\n",
    "# y_test_bin = test_data.connection_category.copy()\n",
    "# #turn our labels into 0 = not attack, 1 = attack\n",
    "# y_test_bin = y_test_bin.apply(lambda x: 0 if x=='normal' else 1)\n",
    "# y_train_bin = y_train_bin.apply(lambda x: 0 if x=='normal' else 1)\n",
    "\n",
    "# #create multi category classifier e.g. normal,u2r,dos... \n",
    "# #these will get loaded slightly differently into the other files\n",
    "# y_train_multi =  train_data.connection_category.copy()\n",
    "# y_test_multi =  test_data.connection_category.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13b8d7d9-45a3-401a-99e4-c79803a9044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(X_train_small, '..\\data\\X_train.csv', index=False)\n",
    "pd.DataFrame.to_csv(X_val, '..\\data\\X_val.csv', index=False)\n",
    "pd.DataFrame.to_csv(X_test, '..\\data\\X_test.csv', index=False)\n",
    "\n",
    "pd.DataFrame.to_csv(y_train_bin, '..\\data\\y_train_bin.csv', index=False)\n",
    "pd.DataFrame.to_csv(y_val_bin, '..\\data\\y_val_bin.csv', index=False)\n",
    "pd.DataFrame.to_csv(y_test_bin, '..\\data\\y_test_bin.csv', index=False)\n",
    "\n",
    "pd.DataFrame(y_train_multi).to_csv('..\\data\\y_train_multi.csv', index=False)\n",
    "pd.DataFrame(y_val_multi).to_csv('..\\data\\y_val_multi.csv', index=False)\n",
    "pd.DataFrame(y_test_multi).to_csv('..\\data\\y_test_multi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d2788-77d5-4891-bb95-de4fd003b668",
   "metadata": {},
   "source": [
    "Code below is for connection_type classification but that would need more tweaking when creating a neural network's architecture. The neural network would have to output some form of distance rather than probability of a certain type of attack, in case some attack type was not seen in training but was seen in test.\n",
    "\n",
    "For example, given the way that we split the data, we have `rootkit`, `ftp_write`, `warezmaster`,`multihop`,`spy`,`phf` attacks that exist either in the training or test data, but not in both (you can see this for yourself by un-commenting the two code cells below and running tehm). These existing in the training data alone is less of an issue but if they only exist in the test data then we may get nonesense classification of a class that we have not seen. One solution to this may be to stratify the data but as seen above when highlighting different types of attacks that exist, attacks like `phf`,`perl`, and `spy` appear less than 5 times each and so even a stratified sample won't be very representative if we are taking a 1:9 test:train split. Some selection process can be used wherein the training data has the first occurence of each connection type and then added on top of a stratified sample. That way the training data will always consist of a 90% + 23 datapoints which will always contain all connection types. This, however, assumes that our dataset is inclusive of all possible attack types, and introducing new data with new attacks would mean our model may not generalise very well.\n",
    "\n",
    "A model selection approach to resolve this would be to create a neural network that outputs some sort of distance from a class rather than a probability of belonging to a class, then assigning a new observation as an `other` class if its distance from all classes exceeds a certian threshold. This, however, feels like it would fall outside the scope of this assessment, and so we do not attempt it, unless we find ourselves with enough time to try this implementation.\n",
    "\n",
    "The code is left below, commented out, for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fc5d62-afb5-4c5c-b807-8e6c0dea7714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create multiclass category for all connection types 'normal','buffer_overflow','perl'...\n",
    "# y_train_allclass = train_data.connection_type.copy()\n",
    "# y_test_allclass = test_data.connection_type.copy()\n",
    "# #as above, factorize then turn into tf.keras categorical\n",
    "# y_train_allclass, train_classes = pd.factorize(y_train_allclass)\n",
    "# y_test_allclass, test_classes = pd.factorize(y_test_allclass)\n",
    "# #turn into tf.keras categorical\n",
    "# y_train_allclass = to_categorical(y_train_allclass, num_classes = len(train_classes))\n",
    "# y_test_allclass = to_categorical(y_test_allclass, num_classes = len(test_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b5a7f5-59fe-4d03-8c30-c170ccb64336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_classes = set(list(train_classes)+list(test_classes))\n",
    "# inc_classes = [c for c in train_classes if c in test_classes]\n",
    "# exc_classes = [c for c in all_classes if c not in inc_classes]\n",
    "\n",
    "# exc_classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assessment4env",
   "language": "python",
   "name": "assessment4env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
